{"metadata": {"language_info": {"pygments_lexer": "ipython2", "nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "2.7.11", "file_extension": ".py", "name": "python", "codemirror_mode": {"name": "ipython", "version": 2}}, "kernelspec": {"name": "python2-spark20", "language": "python", "display_name": "Python 2 with Spark 2.0"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"execution_count": 1, "source": "\nimport ibmos2spark\n\n # @hidden_cell\ncredentials = {\n    'auth_url': 'https://identity.open.softlayer.com',\n    'project_id': '8aa6e0aab6094fdd9838d3e08e7253f3',\n    'region': 'dallas',\n    'user_id': '775a8781e7bf4c0b88ebc086525aa3d7',\n    'username': 'member_78415bb429eb12ae25686a6d27742576ced7a7ca',\n    'password': 'IJ3.9-K=12.]s&r?'\n}\n\nconfiguration_name = 'os_fa1cd21c20344b08a7e27d96dc1f7387_configs'\nbmos = ibmos2spark.bluemix(sc, credentials, configuration_name)\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n# Please read the documentation of PySpark to learn more about the possibilities to load data files.\n# PySpark documentation: https://spark.apache.org/docs/2.0.1/api/python/pyspark.sql.html#pyspark.sql.SparkSession\n# The SparkSession object is already initalized for you.\n# The following variable contains the path to your file on your Object Storage.\n\n", "outputs": [], "metadata": {"collapsed": true}, "cell_type": "code"}, {"execution_count": 2, "source": "path_user = bmos.url('Fall2017', 'user.json.gz')\ndf_users=spark.read.json(path_user)\ndf_users.show(5)\ndf_users.printSchema()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+------+------------+------+--------------------+-------------+\n|average_stars|compliment_cool|compliment_cute|compliment_funny|compliment_hot|compliment_list|compliment_more|compliment_note|compliment_photos|compliment_plain|compliment_profile|compliment_writer| cool|               elite|fans|             friends|funny|  name|review_count|useful|             user_id|yelping_since|\n+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+------+------------+------+--------------------+-------------+\n|          3.8|           5174|            284|            5174|          5175|             78|            299|           1435|             7829|            7397|               569|             1834|16856|[2014, 2016, 2013...| 209|[M19NwFwAXKRZzt8k...|16605|   Cin|         272| 17019|lsSiIjAKVl-QRxKjR...|   2010-07-13|\n|         3.94|           1556|            211|            1556|          1285|            101|            134|           1295|              162|            2134|                74|              402|40110|[2014, 2017, 2011...| 835|[eoSSJzdprj3jxXyi...|10882|Andrea|        2559| 83681|om5ZiponkpRqUNa3p...|   2006-01-18|\n|         4.72|             15|              1|              15|             5|              0|              1|             11|                8|              20|                 0|                1|   55|                  []|  17|[Oa84FFGBw1axX8O6...|    4|  Gabe|         277|    45|-lGwMGHMC_XihFJNK...|   2014-10-31|\n|         3.76|              9|              0|               9|             1|              0|              1|              4|                1|              11|                 0|                3|    4|        [2016, 2017]|  11|[96DJovjKAtExnyBZ...|    4|  Leah|         436|    15|D-ydMTPGWXTVm4_jj...|   2013-04-01|\n|         4.23|            276|              0|             276|            59|              0|              8|             51|              169|             386|                 3|               29| 6006|        [2017, 2016]|  49|[iN0A6QIrEFYoSGHF...|  360|  Juan|         921|  9152|PcvbBOCOcs6_suRDH...|   2012-08-16|\n+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+-----+--------------------+----+--------------------+-----+------+------------+------+--------------------+-------------+\nonly showing top 5 rows\n\nroot\n |-- average_stars: double (nullable = true)\n |-- compliment_cool: long (nullable = true)\n |-- compliment_cute: long (nullable = true)\n |-- compliment_funny: long (nullable = true)\n |-- compliment_hot: long (nullable = true)\n |-- compliment_list: long (nullable = true)\n |-- compliment_more: long (nullable = true)\n |-- compliment_note: long (nullable = true)\n |-- compliment_photos: long (nullable = true)\n |-- compliment_plain: long (nullable = true)\n |-- compliment_profile: long (nullable = true)\n |-- compliment_writer: long (nullable = true)\n |-- cool: long (nullable = true)\n |-- elite: array (nullable = true)\n |    |-- element: long (containsNull = true)\n |-- fans: long (nullable = true)\n |-- friends: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- funny: long (nullable = true)\n |-- name: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- useful: long (nullable = true)\n |-- user_id: string (nullable = true)\n |-- yelping_since: string (nullable = true)\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 3, "source": "print\"Yelp user record count:\",df_users.count()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "Yelp user record count: 1183362\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 4, "source": "df_users.describe('funny','useful','cool').show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+------------------+------------------+------------------+\n|summary|             funny|            useful|              cool|\n+-------+------------------+------------------+------------------+\n|  count|           1183362|           1183362|           1183362|\n|   mean|15.256665331487744|30.294972290812108|20.322260643826656|\n| stddev| 490.7658665490963| 705.8451812603226|  668.138310221103|\n|    min|                 0|                 0|                 0|\n|    max|            192663|            202867|            201062|\n+-------+------------------+------------------+------------------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 5, "source": "df_users.select('user_id','name','funny','useful','cool').sort('cool',ascending=False).show(10)", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-------+------+------+------+\n|             user_id|   name| funny|useful|  cool|\n+--------------------+-------+------+------+------+\n|JjXuiru1_ONzDkYVr...|Richard|192663|202867|201062|\n|0XXIv9a0LWiaCjAku...|  David| 20437| 30843|195341|\n|PhUqhfyk3jdaS0Xb6...|    Des| 24289|166693|175230|\n|6s-g2vFu12OemhiK3...|   Dave| 84527|187179|167181|\n|ax7SnXOTIpatbsmqH...| Rohlin|131408|132117|131781|\n|--2vR0DIsmQ6WfcSz...| Harald|122419|122921|122890|\n|WR6033peFiviFPzAV...|   Dale| 63623|150844|104577|\n|PvSzDcag7vo1e5Zz7...|  Chris|103514|104599|103668|\n|NOUfyJW-BAo_-Cbfo...|  Lolia| 25715| 97256| 96424|\n|XCW5pJCDhvlW76XTS...|    Ivy| 79316| 80151| 79437|\n+--------------------+-------+------+------+------+\nonly showing top 10 rows\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 6, "source": "df_users.corr('funny','compliment_funny')", "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 6, "data": {"text/plain": "0.6871378854374348"}}], "metadata": {}, "cell_type": "code"}, {"execution_count": 8, "source": "df_users.createOrReplaceTempView(\"yelp_users\")\nspark.sql(\"SELECT YEAR(yelping_since) AS yelping_year,COUNT(*) AS user_count FROM yelp_users GROUP BY YEAR(yelping_since)ORDER BY YEAR(yelping_since)\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+----------+\n|yelping_year|user_count|\n+------------+----------+\n|        2004|        73|\n|        2005|       959|\n|        2006|      5812|\n|        2007|     15950|\n|        2008|     31284|\n|        2009|     58336|\n|        2010|     94826|\n|        2011|    142915|\n|        2012|    150292|\n|        2013|    165652|\n|        2014|    181419|\n|        2015|    173071|\n|        2016|    121251|\n|        2017|     41522|\n+------------+----------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 15, "source": "from pyspark.sql.types import*\nssaSchema=StructType([\\\nStructField(\"ssa_year\",IntegerType(),True),\\\nStructField(\"ssa_name\",StringType(),True),\\\nStructField(\"ssa_gender\",StringType(),True),\\\nStructField(\"ssa_count\",IntegerType(),True)])\ndf_gender = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .schema(ssaSchema)\\\n  .load(bmos.url('Fall2017', 'ssa_names_gender.csv'))\nprint\"SSA record count:\",df_gender.count()\ndf_gender.take(5)\ndf_gender.printSchema()\n", "outputs": [{"name": "stdout", "output_type": "stream", "text": "SSA record count: 1891894\nroot\n |-- ssa_year: integer (nullable = true)\n |-- ssa_name: string (nullable = true)\n |-- ssa_gender: string (nullable = true)\n |-- ssa_count: integer (nullable = true)\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 17, "source": "df_gender.createOrReplaceTempView(\"gender\")\nspark.sql(\"SELECT ssa_name,SUM(ssa_count) AS total FROM gender WHERE ssa_gender='F'GROUP BY ssa_name ORDER BY SUM(ssa_count)DESC\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+-------+\n| ssa_name|  total|\n+---------+-------+\n|     Mary|4120692|\n|Elizabeth|1620611|\n| Patricia|1571380|\n| Jennifer|1465243|\n|    Linda|1451809|\n|  Barbara|1433727|\n| Margaret|1244388|\n|    Susan|1121148|\n|  Dorothy|1106575|\n|    Sarah|1069797|\n|  Jessica|1043625|\n|    Helen|1017519|\n|    Nancy|1001671|\n|    Betty| 999275|\n|    Karen| 985097|\n|     Lisa| 964673|\n|     Anna| 883882|\n|   Sandra| 873187|\n|   Ashley| 841259|\n| Kimberly| 833311|\n+---------+-------+\nonly showing top 20 rows\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 18, "source": "spark.sql(\"SELECT ssa_gender,COUNT(DISTINCT ssa_name) AS name_count FROM gender GROUP BY ssa_gender\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+----------+\n|ssa_gender|name_count|\n+----------+----------+\n|         F|     66358|\n|         M|     40337|\n+----------+----------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 19, "source": "spark.sql(\"SELECT COUNT(DISTINCT ssa_name) AS name_cnt FROM gender\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|name_cnt|\n+--------+\n|   96174|\n+--------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 34, "source": "df_women=spark.sql(\"SELECT ssa_name, SUM(ssa_count)AS women_count, 0 AS men_count FROM gender WHERE ssa_gender='F' GROUP BY ssa_name\")\ndf_men=spark.sql(\"SELECT ssa_name, 0 AS women_count, SUM(ssa_count) AS men_count FROM gender WHERE ssa_gender='M' GROUP BY ssa_name\")\ndf_women.unionAll(df_men).createOrReplaceTempView(\"women_men_union\")\nspark.sql(\"SELECT ssa_name, SUM(women_count)AS women, SUM(men_count) AS men FROM women_men_union GROUP BY ssa_name\").createOrReplaceTempView(\"women_men\") \ndf_gender_ratio=spark.sql(\"SELECT ssa_name, women, men, IF(men>women, 2, 1) AS gender, IF(men>women, men/(women+men),women/(women+men))AS genderRatio FROM women_men\")\ndf_gender_ratio.show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+-----+------+------+------------------+\n|ssa_name|women|   men|gender|       genderRatio|\n+--------+-----+------+------+------------------+\n|   Abner|    0|  7440|     2|               1.0|\n|Laurence|  454| 39105|     2|0.9885234712707601|\n| Ephriam|    0|   921|     2|               1.0|\n|Thurston|    0|  3413|     2|               1.0|\n|   Tyler|16245|580385|     2|0.9727720697919984|\n| Rosendo|    0|  5179|     2|               1.0|\n|   Ewart|    0|   131|     2|               1.0|\n|    Nell|26638|    98|     1|0.9963345302214243|\n|    Faye|67691|   518|     1|0.9924056942632205|\n|   Lorne|   50|  4235|     2|0.9883313885647608|\n| Percell|    0|  1064|     2|               1.0|\n|   Fines|    0|    81|     2|               1.0|\n| Normand|    0|  5829|     2|               1.0|\n|Francois|    5|  1677|     2|0.9970273483947681|\n|    Mirl|   55|    87|     2|0.6126760563380281|\n|  Helmut|    0|   451|     2|               1.0|\n|  Clance|    0|   336|     2|               1.0|\n|   Estal|    0|    60|     2|               1.0|\n|  Easter| 5508|    66|     1|0.9881593110871906|\n|    Gola|  306|     5|     1|0.9839228295819936|\n+--------+-----+------+------+------------------+\nonly showing top 20 rows\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 38, "source": "df_users.select(df_users.user_id, df_users.name).createOrReplaceTempView(\"yelp_users\")\ndf_gender_ratio.createOrReplaceTempView(\"gender_ratio\")\ndf_user_gender=spark.sql(\"SELECT U.user_id, U.name, IF(G.gender IS NULL, 3, G.gender) AS user_gender, IF(G.gender IS NULL, 1.00, G.genderRatio) AS gender_ratio FROM yelp_users AS U LEFT JOIN gender_ratio AS G ON U.name=G.ssa_name\")\ndf_user_gender.createOrReplaceTempView(\"user_gender_ratio\")\ndf_user_gender.show(10)", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------+-----------+------------+\n|             user_id|              name|user_gender|gender_ratio|\n+--------------------+------------------+-----------+------------+\n|KVAMAb7X6gf-FTjpv...|         2 S M Art|          3|         1.0|\n|jQq-S5CIiRrgGBXw2...|86 The Bad Reviews|          3|         1.0|\n|jXsHj5vXj_fNbQceD...|       A. Brigitte|          3|         1.0|\n|VCNdLIFlwa4buWYIV...|               A.J|          3|         1.0|\n|E3LyTOlYe0KmB25bq...|               A.J|          3|         1.0|\n|7Ni48EZUbWatCYo7g...|               A.J|          3|         1.0|\n|Gy5L7iJSN0uExQKiv...|               A.J|          3|         1.0|\n|2LPRuLyo5RRmhGeJ7...|              A.a.|          3|         1.0|\n|57NU6K2E1jsWcVf13...|              ANNA|          3|         1.0|\n|W34pNbx4TRDoZ40aL...|              ANNA|          3|         1.0|\n+--------------------+------------------+-----------+------------+\nonly showing top 10 rows\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 39, "source": "spark.sql(\"SELECT COUNT(*) FROM user_gender_ratio WHERE user_gender=3\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(1)|\n+--------+\n|  155836|\n+--------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 41, "source": "df_user_gender=spark.sql(\"SELECT U.user_id, U.name, IF(G.gender IS NULL, 3, G.gender) AS gender_ratio, IF(G.gender IS NULL, 1.00,G.genderRatio)AS gender_ratio FROM yelp_users AS U LEFT JOIN gender_ratio AS G ON LOWER(U.name)=LOWER(G.ssa_name)\")\nspark.sql(\"SELECT COUNT(*) FROM user_gender_ratio WHERE user_gender=3\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(1)|\n+--------+\n|  155836|\n+--------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 42, "source": "spark.sql(\"SELECT COUNT(*) FROM user_gender_ratio WHERE user_gender=3\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(1)|\n+--------+\n|  155836|\n+--------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 46, "source": "df_user_gender=spark.sql(\"SELECT U.user_id, U.name, IF(G.gender IS NULL, 3, G.gender) AS gender_ratio, IF(G.gender IS NULL, 1.00,G.genderRatio)AS gender_ratio FROM yelp_users AS U LEFT JOIN gender_ratio AS G ON LOWER(U.name)=LOWER(G.ssa_name)\")\ndf_user_gender.show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+---------------+------------+------------------+\n|             user_id|           name|gender_ratio|      gender_ratio|\n+--------------------+---------------+------------+------------------+\n|8yuMP766uRPe6sEcx...|         'Nikki|           3|               1.0|\n|MS_IRLwpy-TUGNyUI...|1Southerngyrl76|           3|               1.0|\n|k7aF28JCVxi14O4qO...|         A-dogg|           3|               1.0|\n|WwsMmD9R4Oz0ZqmsY...|       Advice4u|           3|               1.0|\n|Zu7gGW6dlGIf3iDG9...|       Adwinnie|           3|               1.0|\n|D809l3fCdGAKv897u...|       Agnes C.|           3|               1.0|\n|qMubZnWM_lLRXqYwE...|      Agustinus|           3|               1.0|\n|pivG5Kp8WdoCekuM6...|          Ailis|           1|               1.0|\n|hJPPMAaczO7VgE-sC...|          Ailis|           1|               1.0|\n|CiK2bpgH8G35aofeo...|       Air Rick|           3|               1.0|\n|r_yzcbcHGOgtmGKRC...|          Akeem|           2|               1.0|\n|YDwKuB3c5T0WqKokN...|          Akeem|           2|               1.0|\n|Al8Qo08M8K2Rq70Gk...|          Akeem|           2|               1.0|\n|m4eHGySVM2lL-Sfju...|          Akeem|           2|               1.0|\n|UHH66JQXFHyXJVgOg...|          Akeem|           2|               1.0|\n|6FasnS3e53f3fW_zw...|            Ako|           2|0.8148148148148148|\n|-CLLKoyqS9zIJx3V_...|            Ako|           2|0.8148148148148148|\n|gvjAEZJP81A7ksst8...|            Ako|           2|0.8148148148148148|\n|kU7SeXInsWAQThu-_...|          Aleck|           2|               1.0|\n|DMEO6ghSh1aBfT53B...|          Aleck|           2|               1.0|\n+--------------------+---------------+------------+------------------+\nonly showing top 20 rows\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 50, "source": "df_user_gender=spark.sql(\"SELECT U.user_id, U.name, IF(G.gender IS NULL, 3, G.gender) AS gender_ratio, IF(G.gender IS NULL, 1.00,G.genderRatio)AS gender_ratio FROM yelp_users AS U LEFT JOIN gender_ratio AS G ON LOWER(U.name)=LOWER(G.ssa_name)\")\nspark.sql(\"SELECT COUNT(*)FROM user_gender_ratio WHERE user_gender=3\").show()", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(1)|\n+--------+\n|  155836|\n+--------+\n\n"}], "metadata": {}, "cell_type": "code"}, {"execution_count": 53, "source": "df_users.select(df_users.user_id, df_users.name).createOrReplaceTempView(\"yelp_users\")\ndf_gender_ratio.createOrReplaceTempView(\"gender_ratio\")\ndf_user_gender=spark.sql(\"SELECT U.user_id, U.name, IF(G.gender IS NULL, 3, G.gender) AS user_gender, IF(G.gender IS NULL, 1.00, G.genderRatio) AS gender_ratio FROM yelp_users AS U LEFT JOIN gender_ratio AS G ON LOWER(U.name)=LOWER(G.ssa_name)\")\ndf_user_gender.createOrReplaceTempView(\"user_gender_ratio\")\nspark.sql(\"SELECT COUNT(*) FROM user_gender_ratio WHERE user_gender=3\").show()\n", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(1)|\n+--------+\n|  133373|\n+--------+\n\n"}], "metadata": {}, "cell_type": "code"}]}